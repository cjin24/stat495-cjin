%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/



@book{duda1973pattern,
  title={Pattern classification and scene analysis},
  author={Duda, Richard O and Hart, Peter E and others},
  volume={3},
  year={1973},
  publisher={Wiley New York}
}

@book{bouguila2020mixture,
  title={Mixture models and applications},
  author={Bouguila, Nizar and Fan, Wentao},
  year={2020},
  publisher={Springer}
}

@article{yu2015gaussian,
  title={Gaussian mixture models},
  author={Yu, Dong and Deng, Li and Yu, Dong and Deng, Li},
  journal={Automatic Speech Recognition: A Deep Learning Approach},
  pages={13--21},
  year={2015},
  publisher={Springer}
}

@article{do2008expectation,
  title={What is the expectation maximization algorithm?},
  author={Do, Chuong B and Batzoglou, Serafim},
  journal={Nature biotechnology},
  volume={26},
  number={8},
  pages={897--899},
  year={2008},
  publisher={Nature Publishing Group US New York}
}

@article{reynolds2009gaussian,
  title={Gaussian mixture models.},
  author={Reynolds, Douglas A and others},
  journal={Encyclopedia of biometrics},
  volume={741},
  number={659-663},
  year={2009},
  publisher={Berlin, Springer}
}

@inproceedings{wan2019novel,
  title={A novel gaussian mixture model for classification},
  author={Wan, Huan and Wang, Hui and Scotney, Bryan and Liu, Jun},
  booktitle={2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)},
  pages={3298--3303},
  year={2019},
  organization={IEEE}
}

@article{kumar2022gaussian,
  title={Gaussian mixture models: What are they \& when to use},
  author={Kumar, A},
  journal={Online, Apr},
  year={2022}
}

@article{reynolds1995robust,
  title={Robust text-independent speaker identification using Gaussian mixture speaker models},
  author={Reynolds, Douglas A and Rose, Richard C},
  journal={IEEE transactions on speech and audio processing},
  volume={3},
  number={1},
  pages={72--83},
  year={1995},
  publisher={IEEE}
}

@article{satoh2023improved,
  title={Improved performance of data-driven simulator of liquid rocket engine under varying operating conditions},
  author={Satoh, Daiwa and Omata, Noriyasu and Tsutsumi, Seiji and Hashimoto, Tomoyuki and Sato, Masaki and Kimura, Toshiya and Abe, Masaharu},
  journal={Acta Astronautica},
  year={2023},
  publisher={Elsevier}
}

@article{qing2023analyzing,
  title={Analyzing the impact of fare-free public transport policies on crowding patterns at stations using crowdsensing data},
  author={Qing-Long, Lu and Mahajan, Vishal and Cheng, Lyu and Antoniou, Constantinos},
  journal={Preprint},
  year={2023}
}

@article{xi2023deep,
  title={Deep Learning for Deep Earthquakes: Insights from OBS Observations of the Tonga Subduction Zone},
  author={Xi, Ziyi and Wei, Songqiao Shawn and Zhu, Weiqiang and Beroza, Greg and Jie, Yaqi and Saloor, Nooshin},
  year={2023},
  publisher={EarthArXiv}
}

@article{huang2023gaussian,
  title={Gaussian Mixture Model based pattern recognition for understanding the long-term impact of COVID-19 on energy consumption of public buildings},
  author={Huang, Zefeng and Gou, Zhonghua},
  journal={Journal of Building Engineering},
  volume={72},
  pages={106653},
  year={2023},
  publisher={Elsevier}
}



@article{Girolami05,
	Abstract = {To provide a parsimonious generative representation of the sequential activity of a number of individuals within a population there is a necessary tradeoff between the definition of individual specific and global 
representations. A linear-time algorithm is proposed that defines a distributed predictive model for finite state symbolic sequences which represent the traces of the activity of a number of individuals within a group. The algorithm is based on a straightforward generalization of latent Dirichlet allocation to time-invariant Markov chains of arbitrary order. The modelling assumption made is that the possibly heterogeneous behavior of individuals may be represented by a relatively small number of simple and common behavioral traits which may interleave randomly according to an individual-specific distribution. The results of an empirical study on three different application domains indicate that this modelling approach provides an efficient low-complexity and intuitively interpretable representation scheme which is reflected by improved prediction performance over comparable models.},
	Annote = {Builds a mixed-membership model where the basis profiles are markov chains of varying order. 
Uses two types of estimation: Variational approximation, and "maximum a posteriori" (MAP)
Fits model on 3 different data sets of user-log data: actions in a word processor, sequences of calls to different geographic regions (UK), and finally web page browsing. 

Compares models on "perplexity" which they define as the exponential of the negative-normalized log-likelihood.  (Might be a standard markov-chain goodness of fit measure, or it might be more standard to ML)
They use t-tests and non-parametric Wilcoxon Rank-Sum tests to test for significant differences in perplexity.

They call their model a "simplical mixture of markov chains" and cite Minka and Lafferty 2002. 

For the zero^th order Markov model (when no memory is assumed in the markov process), then their model reduces to a multinomial LDA model. 

They also claim that Hofmann's pLSA algorithm is equivalent to LDA when the MAP estimator is calculated through an iterative convergence method. Suggests that LDA is an improvement over pLSA because of the estimation method used.  Cites Lappalainen and Miskin (2000) on the weakness of MAP estimators. 

For all the data sets, the mixed-membership model offers better results. Better on the goodness-of-fit measures and more interpretable results.  The differences were clearer on the bigger data sets with larger state-spaces. 

Data Structure:  only 1 item per model - the sequences (J=1)
	many replications of each item (big R) 

They offer some additional comments on computational algorithms and computational time.},
	Author = {Mark Girolami and Ata Kaban},
	Date-Added = {2013-06-25 19:41:00 +0000},
	Date-Modified = {2013-06-25 19:41:00 +0000},
	Journal = {Data Mining and Knowledge Discovery},
	Keywords = {Latent Dirichlet Allocation, markov chains, Mixture models, user profiling, mixed membership, variational approximation},
	Pages = {175-196},
	Title = {Sequential Activity Profiling: Latent Dirichlet Allocation of Markov Chains},
	Volume = {10},
	Year = {2005}
}
